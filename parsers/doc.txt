project/
├── parsers/
│   ├── __init__.py
│   ├── network_traffic.py -> содержит класс для автоматизированной работы с браузером для получения cookies, заголовков и токенов
│   │                         доступа из источников парсинга.
│   ├── service.py -> содержит класс для работы с базой данных (наследуется от cache.Cache). этот класс по-сути прослойка между непосредственно данными и
│   │                 прямыми методами для записи из database.crud.catalog. класс управляет сессиями, кешем с айдишниками базы данных. общий для всех парсеров
│   ├── cache.py ->  содержит класс с кешем базы данных. Класс представляет из себя словари, где имя записи из бд - ключ словаря,
│   │                значение словаря - айдишник этой записи бд (первичный ключ). Это сделано для быстрого доступа к часто используемым записям
│   ├── edostavka_by/ -> пакет для скрапинга одноимённого интернет-магазина
│   │   ├── __init__.py
│   │   ├── controller.py -> основной модуль, внутри которого осуществляется создание экземпляров классов для парсинга и базы
│   │   │                    данных а так же из запуск и совместную работу с обменом данными.
│   │   ├── schemas.py -> классы pydantic для парсинга json документов ответа сайта
│   │   ├── spider_sync.py -> основной класс парсинга сайта, содержащий синхронные методы работы. crawl функция содержит
│   │   │                     логику обхода сайта-источника и порционный возврат готовых данных во внешнюю область (controller)



